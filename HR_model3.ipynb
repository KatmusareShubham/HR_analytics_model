{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "acc = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing HR train file\n",
    "df = pd.read_csv('HR_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing on test data\n",
    "df2 = pd.read_csv('HR_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54808, 14)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "#df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id                0\n",
       "department                 0\n",
       "region                     0\n",
       "education               2409\n",
       "gender                     0\n",
       "recruitment_channel        0\n",
       "no_of_trainings            0\n",
       "age                        0\n",
       "previous_year_rating    4124\n",
       "length_of_service          0\n",
       "KPIs_met >80%              0\n",
       "awards_won?                0\n",
       "avg_training_score         0\n",
       "is_promoted                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id                0\n",
       "department                 0\n",
       "region                     0\n",
       "education               1034\n",
       "gender                     0\n",
       "recruitment_channel        0\n",
       "no_of_trainings            0\n",
       "age                        0\n",
       "previous_year_rating    1812\n",
       "length_of_service          0\n",
       "KPIs_met >80%              0\n",
       "awards_won?                0\n",
       "avg_training_score         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    " # let's create a variable to replace NA with a random sample\n",
    "\n",
    "def impute_na(df, variable):\n",
    "    # random sampling\n",
    "    #df[variable] = df[variable]\n",
    "        \n",
    "    # extract the random sample to fill the na\n",
    "    random_sample = df[variable].dropna().sample(df[variable].isnull().sum(), \n",
    "                                                 random_state=0)\n",
    "    \n",
    "    # pandas needs to have the same index in order to merge datasets\n",
    "    random_sample.index = df[df[variable].isnull()].index\n",
    "    \n",
    "    df.loc[df[variable].isnull(), variable] = random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_na(df,'education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_na(df2,'education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['previous_year_rating'] = df['previous_year_rating'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['previous_year_rating'] = df2['previous_year_rating'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id             0\n",
       "department              0\n",
       "region                  0\n",
       "education               0\n",
       "gender                  0\n",
       "recruitment_channel     0\n",
       "no_of_trainings         0\n",
       "age                     0\n",
       "previous_year_rating    0\n",
       "length_of_service       0\n",
       "KPIs_met >80%           0\n",
       "awards_won?             0\n",
       "avg_training_score      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.isna().sum()\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id             0\n",
       "department              0\n",
       "region                  0\n",
       "education               0\n",
       "gender                  0\n",
       "recruitment_channel     0\n",
       "no_of_trainings         0\n",
       "age                     0\n",
       "previous_year_rating    0\n",
       "length_of_service       0\n",
       "KPIs_met >80%           0\n",
       "awards_won?             0\n",
       "avg_training_score      0\n",
       "is_promoted             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns_WOE=df.columns[1:-2]\n",
    "#columns_WOE\n",
    "#from category_encoders import WOEEncoder\n",
    "#woe_enc=WOEEncoder(cols=columns_WOE,random_state=17).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding\n",
    "\n",
    "prob_df = df.groupby(['department'])['is_promoted'].mean()\n",
    "prob_df = pd.DataFrame(prob_df)\n",
    "prob_df['Not_promoted'] = 1-prob_df.is_promoted\n",
    "\n",
    "\n",
    "prob_df.loc[prob_df['is_promoted'] == 0, 'is_promoted'] = 0.00001\n",
    "prob_df.loc[prob_df['Not_promoted'] == 0, 'Not_promoted'] = 0.00001\n",
    "\n",
    "prob_df['WoE'] = np.log(prob_df['is_promoted']/prob_df['Not_promoted'])\n",
    "\n",
    "woe_labels = prob_df['WoE'].to_dict()\n",
    "\n",
    "df['dept_WOE'] = df.department.map(woe_labels)\n",
    "df2['dept_WOE'] = df2.department.map(woe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = df.groupby(['region'])['is_promoted'].mean()\n",
    "prob_df = pd.DataFrame(prob_df)\n",
    "prob_df['Not_promoted'] = 1-prob_df.is_promoted\n",
    "\n",
    "\n",
    "prob_df.loc[prob_df['is_promoted'] == 0, 'is_promoted'] = 0.00001\n",
    "prob_df.loc[prob_df['Not_promoted'] == 0, 'Not_promoted'] = 0.00001\n",
    "\n",
    "prob_df['WoE'] = np.log(prob_df['is_promoted']/prob_df['Not_promoted'])\n",
    "\n",
    "woe_labels = prob_df['WoE'].to_dict()\n",
    "\n",
    "df['region_WOE'] = df.region.map(woe_labels)\n",
    "df2['region_WOE'] = df2.region.map(woe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = df.groupby(['education'])['is_promoted'].mean()\n",
    "prob_df = pd.DataFrame(prob_df)\n",
    "prob_df['Not_promoted'] = 1-prob_df.is_promoted\n",
    "\n",
    "\n",
    "prob_df.loc[prob_df['is_promoted'] == 0, 'is_promoted'] = 0.00001\n",
    "prob_df.loc[prob_df['Not_promoted'] == 0, 'Not_promoted'] = 0.00001\n",
    "\n",
    "prob_df['WoE'] = np.log(prob_df['is_promoted']/prob_df['Not_promoted'])\n",
    "\n",
    "woe_labels = prob_df['WoE'].to_dict()\n",
    "\n",
    "df['education_WOE'] = df.education.map(woe_labels)\n",
    "df2['education_WOE'] = df2.education.map(woe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = df.groupby(['gender'])['is_promoted'].mean()\n",
    "prob_df = pd.DataFrame(prob_df)\n",
    "prob_df['Not_promoted'] = 1-prob_df.is_promoted\n",
    "\n",
    "\n",
    "prob_df.loc[prob_df['is_promoted'] == 0, 'is_promoted'] = 0.00001\n",
    "prob_df.loc[prob_df['Not_promoted'] == 0, 'Not_promoted'] = 0.00001\n",
    "\n",
    "prob_df['WoE'] = np.log(prob_df['is_promoted']/prob_df['Not_promoted'])\n",
    "\n",
    "woe_labels = prob_df['WoE'].to_dict()\n",
    "\n",
    "df['gender_WOE'] = df.gender.map(woe_labels)\n",
    "df2['gender_WOE'] = df2.gender.map(woe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = df.groupby(['recruitment_channel'])['is_promoted'].mean()\n",
    "prob_df = pd.DataFrame(prob_df)\n",
    "prob_df['Not_promoted'] = 1-prob_df.is_promoted\n",
    "\n",
    "\n",
    "prob_df.loc[prob_df['is_promoted'] == 0, 'is_promoted'] = 0.00001\n",
    "prob_df.loc[prob_df['Not_promoted'] == 0, 'Not_promoted'] = 0.00001\n",
    "\n",
    "prob_df['WoE'] = np.log(prob_df['is_promoted']/prob_df['Not_promoted'])\n",
    "\n",
    "woe_labels = prob_df['WoE'].to_dict()\n",
    "\n",
    "df['recruitment_channel_WOE'] = df.recruitment_channel.map(woe_labels)\n",
    "df2['recruitment_channel_WOE'] = df2.recruitment_channel.map(woe_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = df.groupby(['no_of_trainings'])['is_promoted'].mean()\n",
    "prob_df = pd.DataFrame(prob_df)\n",
    "prob_df['Not_promoted'] = 1-prob_df.is_promoted\n",
    "\n",
    "\n",
    "prob_df.loc[prob_df['is_promoted'] == 0, 'is_promoted'] = 0.00001\n",
    "prob_df.loc[prob_df['Not_promoted'] == 0, 'Not_promoted'] = 0.00001\n",
    "\n",
    "prob_df['WoE'] = np.log(prob_df['is_promoted']/prob_df['Not_promoted'])\n",
    "\n",
    "woe_labels = prob_df['WoE'].to_dict()\n",
    "\n",
    "df['trainings_WOE'] = df.no_of_trainings.map(woe_labels)\n",
    "df2['trainings_WOE'] = df2.no_of_trainings.map(woe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = df.groupby(['avg_training_score'])['is_promoted'].mean()\n",
    "prob_df = pd.DataFrame(prob_df)\n",
    "prob_df['Not_promoted'] = 1-prob_df.is_promoted\n",
    "\n",
    "\n",
    "prob_df.loc[prob_df['is_promoted'] == 0, 'is_promoted'] = 0.00001\n",
    "prob_df.loc[prob_df['Not_promoted'] == 0, 'Not_promoted'] = 0.00001\n",
    "\n",
    "prob_df['WoE'] = np.log(prob_df['is_promoted']/prob_df['Not_promoted'])\n",
    "\n",
    "woe_labels = prob_df['WoE'].to_dict()\n",
    "\n",
    "df['avg_training_score_WOE'] = df.avg_training_score.map(woe_labels)\n",
    "df2['avg_training_score_WOE'] = df2.avg_training_score.map(woe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>dept_WOE</th>\n",
       "      <th>region_WOE</th>\n",
       "      <th>education_WOE</th>\n",
       "      <th>gender_WOE</th>\n",
       "      <th>recruitment_channel_WOE</th>\n",
       "      <th>trainings_WOE</th>\n",
       "      <th>avg_training_score_WOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.555904</td>\n",
       "      <td>-2.126523</td>\n",
       "      <td>-2.235082</td>\n",
       "      <td>-2.314444</td>\n",
       "      <td>-2.376107</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-3.250762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.311829</td>\n",
       "      <td>-2.048659</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.389825</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-2.682113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.555904</td>\n",
       "      <td>-2.740231</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.376107</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-3.146305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.555904</td>\n",
       "      <td>-2.025070</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.389825</td>\n",
       "      <td>-2.501571</td>\n",
       "      <td>-3.146305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.115565</td>\n",
       "      <td>-2.694911</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.389825</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-2.062347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  previous_year_rating  length_of_service  KPIs_met >80%  awards_won?  \\\n",
       "0   35                   5.0                  8              1            0   \n",
       "1   30                   5.0                  4              0            0   \n",
       "2   34                   3.0                  7              0            0   \n",
       "3   39                   1.0                 10              0            0   \n",
       "4   45                   3.0                  2              0            0   \n",
       "\n",
       "   is_promoted  dept_WOE  region_WOE  education_WOE  gender_WOE  \\\n",
       "0            0 -2.555904   -2.126523      -2.235082   -2.314444   \n",
       "1            0 -2.311829   -2.048659      -2.435100   -2.400278   \n",
       "2            0 -2.555904   -2.740231      -2.435100   -2.400278   \n",
       "3            0 -2.555904   -2.025070      -2.435100   -2.400278   \n",
       "4            0 -2.115565   -2.694911      -2.435100   -2.400278   \n",
       "\n",
       "   recruitment_channel_WOE  trainings_WOE  avg_training_score_WOE  \n",
       "0                -2.376107      -2.336974               -3.250762  \n",
       "1                -2.389825      -2.336974               -2.682113  \n",
       "2                -2.376107      -2.336974               -3.146305  \n",
       "3                -2.389825      -2.501571               -3.146305  \n",
       "4                -2.389825      -2.336974               -2.062347  "
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['department']\n",
    "del df['region']\n",
    "del df['education']\n",
    "del df['gender']\n",
    "del df['recruitment_channel']\n",
    "del df['no_of_trainings']\n",
    "del df['avg_training_score']\n",
    "del df2['department']\n",
    "del df2['region']\n",
    "del df2['education']\n",
    "del df2['gender']\n",
    "del df2['recruitment_channel']\n",
    "del df2['no_of_trainings']\n",
    "del df2['avg_training_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['employee_id']\n",
    "del df2['employee_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>dept_WOE</th>\n",
       "      <th>region_WOE</th>\n",
       "      <th>education_WOE</th>\n",
       "      <th>gender_WOE</th>\n",
       "      <th>recruitment_channel_WOE</th>\n",
       "      <th>trainings_WOE</th>\n",
       "      <th>avg_training_score_WOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.555904</td>\n",
       "      <td>-2.126523</td>\n",
       "      <td>-2.235082</td>\n",
       "      <td>-2.314444</td>\n",
       "      <td>-2.376107</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-3.250762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.311829</td>\n",
       "      <td>-2.048659</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.389825</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-2.682113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.555904</td>\n",
       "      <td>-2.740231</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.376107</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-3.146305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.555904</td>\n",
       "      <td>-2.025070</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.389825</td>\n",
       "      <td>-2.501571</td>\n",
       "      <td>-3.146305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.115565</td>\n",
       "      <td>-2.694911</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.389825</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-2.062347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  previous_year_rating  length_of_service  KPIs_met >80%  awards_won?  \\\n",
       "0   35                   5.0                  8              1            0   \n",
       "1   30                   5.0                  4              0            0   \n",
       "2   34                   3.0                  7              0            0   \n",
       "3   39                   1.0                 10              0            0   \n",
       "4   45                   3.0                  2              0            0   \n",
       "\n",
       "   is_promoted  dept_WOE  region_WOE  education_WOE  gender_WOE  \\\n",
       "0            0 -2.555904   -2.126523      -2.235082   -2.314444   \n",
       "1            0 -2.311829   -2.048659      -2.435100   -2.400278   \n",
       "2            0 -2.555904   -2.740231      -2.435100   -2.400278   \n",
       "3            0 -2.555904   -2.025070      -2.435100   -2.400278   \n",
       "4            0 -2.115565   -2.694911      -2.435100   -2.400278   \n",
       "\n",
       "   recruitment_channel_WOE  trainings_WOE  avg_training_score_WOE  \n",
       "0                -2.376107      -2.336974               -3.250762  \n",
       "1                -2.389825      -2.336974               -2.682113  \n",
       "2                -2.376107      -2.336974               -3.146305  \n",
       "3                -2.389825      -2.501571               -3.146305  \n",
       "4                -2.389825      -2.336974               -2.062347  "
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, [0,1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12]].values\n",
    "y = df.iloc[:, 5].values\n",
    "\n",
    "X2 = df.iloc[:].values\n",
    "#y = df.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, \n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "#scaling for test model is pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>dept_WOE</th>\n",
       "      <th>region_WOE</th>\n",
       "      <th>education_WOE</th>\n",
       "      <th>gender_WOE</th>\n",
       "      <th>recruitment_channel_WOE</th>\n",
       "      <th>trainings_WOE</th>\n",
       "      <th>avg_training_score_WOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.555904</td>\n",
       "      <td>-2.126523</td>\n",
       "      <td>-2.235082</td>\n",
       "      <td>-2.314444</td>\n",
       "      <td>-2.376107</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-3.250762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.311829</td>\n",
       "      <td>-2.048659</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.389825</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-2.682113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.555904</td>\n",
       "      <td>-2.740231</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.376107</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-3.146305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.555904</td>\n",
       "      <td>-2.025070</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.389825</td>\n",
       "      <td>-2.501571</td>\n",
       "      <td>-3.146305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.115565</td>\n",
       "      <td>-2.694911</td>\n",
       "      <td>-2.435100</td>\n",
       "      <td>-2.400278</td>\n",
       "      <td>-2.389825</td>\n",
       "      <td>-2.336974</td>\n",
       "      <td>-2.062347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  previous_year_rating  length_of_service  KPIs_met >80%  awards_won?  \\\n",
       "0   35                   5.0                  8              1            0   \n",
       "1   30                   5.0                  4              0            0   \n",
       "2   34                   3.0                  7              0            0   \n",
       "3   39                   1.0                 10              0            0   \n",
       "4   45                   3.0                  2              0            0   \n",
       "\n",
       "   is_promoted  dept_WOE  region_WOE  education_WOE  gender_WOE  \\\n",
       "0            0 -2.555904   -2.126523      -2.235082   -2.314444   \n",
       "1            0 -2.311829   -2.048659      -2.435100   -2.400278   \n",
       "2            0 -2.555904   -2.740231      -2.435100   -2.400278   \n",
       "3            0 -2.555904   -2.025070      -2.435100   -2.400278   \n",
       "4            0 -2.115565   -2.694911      -2.435100   -2.400278   \n",
       "\n",
       "   recruitment_channel_WOE  trainings_WOE  avg_training_score_WOE  \n",
       "0                -2.376107      -2.336974               -3.250762  \n",
       "1                -2.389825      -2.336974               -2.682113  \n",
       "2                -2.376107      -2.336974               -3.146305  \n",
       "3                -2.389825      -2.501571               -3.146305  \n",
       "4                -2.389825      -2.336974               -2.062347  "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.difference(['is_promoted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KPIs_met >80%', 'age', 'avg_training_score_WOE', 'awards_won?',\n",
       "       'dept_WOE', 'education_WOE', 'gender_WOE', 'length_of_service',\n",
       "       'previous_year_rating', 'recruitment_channel_WOE', 'region_WOE',\n",
       "       'trainings_WOE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def feature_select(X, y, cols, cutoff):\n",
    "    Classifier = RandomForestClassifier(n_estimators = 150, random_state = 0)\n",
    "    Classifier.fit(X, y)\n",
    "    feat_imps = pd.concat([pd.DataFrame(cols, columns=['Features']),\n",
    "                       pd.DataFrame(Classifier.feature_importances_, columns=['Importances'])],\n",
    "                     axis=1)\n",
    "    feat_imps = feat_imps.sort_values(['Importances'], ascending=False)\n",
    "    feat_imps['Cumulative Importances'] = feat_imps['Importances'].cumsum()\n",
    "    feat_imps = feat_imps[feat_imps['Cumulative Importances'] < cutoff]\n",
    "    return feat_imps['Features'].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols = feature_select(X, y, cols, 0.990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trainings_WOE',\n",
       " 'KPIs_met >80%',\n",
       " 'gender_WOE',\n",
       " 'avg_training_score_WOE',\n",
       " 'education_WOE',\n",
       " 'age',\n",
       " 'awards_won?',\n",
       " 'recruitment_channel_WOE',\n",
       " 'dept_WOE',\n",
       " 'region_WOE',\n",
       " 'previous_year_rating']"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[imp_cols].values\n",
    "y = df.iloc[:, 5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.33697416,  1.        , -2.31444361, ..., -2.55590356,\n",
       "        -2.12652297,  5.        ],\n",
       "       [-2.33697416,  0.        , -2.40027805, ..., -2.31182865,\n",
       "        -2.04865924,  5.        ],\n",
       "       [-2.33697416,  0.        , -2.40027805, ..., -2.55590356,\n",
       "        -2.7402312 ,  3.        ],\n",
       "       ...,\n",
       "       [-2.33697416,  1.        , -2.40027805, ..., -2.24634537,\n",
       "        -2.25310504,  5.        ],\n",
       "       [-2.33697416,  0.        , -2.40027805, ..., -2.55590356,\n",
       "        -3.94158181,  1.        ],\n",
       "       [-2.33697416,  0.        , -2.40027805, ..., -2.82015264,\n",
       "        -2.04865924,  1.        ]])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, \n",
    "                                                    random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.33697416,  0.        , -2.40027805, ..., -2.31182865,\n",
       "        -2.04865924,  4.        ],\n",
       "       [-2.33697416,  1.        , -2.40027805, ..., -2.24634537,\n",
       "        -2.51274145,  5.        ],\n",
       "       [-2.33697416,  0.        , -2.40027805, ..., -2.31182865,\n",
       "        -2.44063105,  2.        ],\n",
       "       ...,\n",
       "       [-2.33697416,  0.        , -2.40027805, ..., -2.31182865,\n",
       "        -2.79404065,  1.        ],\n",
       "       [-2.50157143,  1.        , -2.31444361, ..., -2.11556502,\n",
       "        -2.04865924,  5.        ],\n",
       "       [-2.33697416,  0.        , -2.31444361, ..., -2.31182865,\n",
       "        -2.45519018,  3.        ]])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "#scaling for test model is pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smote nahi ho rha hai \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "X_test_res, y_test_res = sm.fit_sample(X_test, y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barnali PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 0)\n",
    "lr.fit(X_train_res, y_train_res)\n",
    "models.append('Logistic Regression HR Analytics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, \n",
    "                             recall_score, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for LR: \n",
      " [[11012  4037]\n",
      " [  362  1032]]\n",
      "Accuracy for LR: \n",
      " 0.7324697439639969\n",
      "Precision for LR: \n",
      " 0.20359045176563426\n",
      "Recall for LR: \n",
      " 0.7403156384505022\n",
      "f1_score for LR: \n",
      " 0.31935633606684205\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix for LR: \\n',confusion_matrix(y_test, lr.predict(X_test)))\n",
    "print('Accuracy for LR: \\n',accuracy_score(y_test, lr.predict(X_test)))\n",
    "acc.append(accuracy_score(y_test, lr.predict(X_test)))\n",
    "print('Precision for LR: \\n',precision_score(y_test, lr.predict(X_test)))\n",
    "precision.append(precision_score(y_test, lr.predict(X_test)))\n",
    "print('Recall for LR: \\n',recall_score(y_test, lr.predict(X_test)))\n",
    "recall.append(recall_score(y_test, lr.predict(X_test)))\n",
    "print('f1_score for LR: \\n',f1_score(y_test, lr.predict(X_test)))\n",
    "f1.append(f1_score(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy', \n",
    "                            max_depth=4 ,\n",
    "                            random_state = 0)\n",
    "dt.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for DTrees: \n",
      " [[11081  3968]\n",
      " [ 2924 12125]]\n",
      "Accuracy for DTrees: \n",
      " 0.7710146853611536\n",
      "Precision for DTrees: \n",
      " 0.7534331697011123\n",
      "Recall for DTrees: \n",
      " 0.8057013755066782\n",
      "f1_score for DTrees: \n",
      " 0.7786911566373387\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix for DTrees: \\n',confusion_matrix(y_test_res, dt.predict(X_test_res)))\n",
    "print('Accuracy for DTrees: \\n',accuracy_score(y_test_res, dt.predict(X_test_res)))\n",
    "acc.append(accuracy_score(y_test_res, dt.predict(X_test_res)))\n",
    "print('Precision for DTrees: \\n',precision_score(y_test_res, dt.predict(X_test_res)))\n",
    "precision.append(precision_score(y_test_res, dt.predict(X_test_res)))\n",
    "print('Recall for DTrees: \\n',recall_score(y_test_res, dt.predict(X_test_res)))\n",
    "recall.append(recall_score(y_test_res, dt.predict(X_test_res)))\n",
    "print('f1_score for DTrees: \\n',f1_score(y_test_res, dt.predict(X_test_res)))\n",
    "f1.append(f1_score(y_test_res, dt.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=11, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 11, criterion = 'entropy', \n",
    "                                    random_state = 0)\n",
    "rf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for RF: \n",
      " [[14540   509]\n",
      " [ 2615 12434]]\n",
      "Accuracy for RF: \n",
      " 0.8962057279553459\n",
      "Precision for RF: \n",
      " 0.9606737232480878\n",
      "Recall for RF: \n",
      " 0.8262343012824772\n",
      "f1_score for RF: \n",
      " 0.8883966847670763\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix for RF: \\n',confusion_matrix(y_test_res, rf.predict(X_test_res)))\n",
    "print('Accuracy for RF: \\n',accuracy_score(y_test_res, rf.predict(X_test_res)))\n",
    "acc.append(accuracy_score(y_test_res, rf.predict(X_test_res)))\n",
    "print('Precision for RF: \\n',precision_score(y_test_res, rf.predict(X_test_res)))\n",
    "precision.append(precision_score(y_test_res, rf.predict(X_test_res)))\n",
    "print('Recall for RF: \\n',recall_score(y_test_res, rf.predict(X_test_res)))\n",
    "recall.append(recall_score(y_test_res, rf.predict(X_test_res)))\n",
    "print('f1_score for RF: \\n',f1_score(y_test_res, rf.predict(X_test_res)))\n",
    "f1.append(f1_score(y_test_res, rf.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=15, random_state=40)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb = AdaBoostClassifier(base_estimator=dt, n_estimators=15, \n",
    "                         algorithm='SAMME.R', random_state=40)\n",
    "adb.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Adaboost: \n",
      " [[14372   677]\n",
      " [ 1303 13746]]\n",
      "Accuracy for Adaboost: \n",
      " 0.9342148979998671\n",
      "Precision for Adaboost: \n",
      " 0.9530610829924426\n",
      "Recall for Adaboost: \n",
      " 0.9134161738321483\n",
      "f1_score for Adaboost: \n",
      " 0.9328175895765473\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix for Adaboost: \\n',confusion_matrix(y_test_res, adb.predict(X_test_res)))\n",
    "print('Accuracy for Adaboost: \\n',accuracy_score(y_test_res, adb.predict(X_test_res)))\n",
    "acc.append(accuracy_score(y_test_res, adb.predict(X_test_res)))\n",
    "print('Precision for Adaboost: \\n',precision_score(y_test_res, adb.predict(X_test_res)))\n",
    "precision.append(precision_score(y_test_res, adb.predict(X_test_res)))\n",
    "print('Recall for Adaboost: \\n',recall_score(y_test_res, adb.predict(X_test_res)))\n",
    "recall.append(recall_score(y_test_res,adb.predict(X_test_res)))\n",
    "print('f1_score for Adaboost: \\n',f1_score(y_test_res, adb.predict(X_test_res)))\n",
    "f1.append(f1_score(y_test_res, adb.predict(X_test_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\"n_estimators\": [15, 20, 25],\n",
    "              \"criterion\":['gini','entropy'],\n",
    "              \"max_depth\": [4, 6, 8],\n",
    "              \"min_samples_split\": [10, 20, 30],\n",
    "              \"min_samples_leaf\": [1, 5, 15],\n",
    "              \"min_weight_fraction_leaf\": [0.1, 0.05, 0.005]}\n",
    "grid_search = GridSearchCV(estimator = rf,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=11, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [15, 20, 25], 'criterion': ['gini', 'entropy'], 'max_depth': [4, 6, 8], 'min_samples_split': [10, 20, 30], 'min_samples_leaf': [1, 5, 15], 'min_weight_fraction_leaf': [0.1, 0.05, 0.005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 8,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'min_weight_fraction_leaf': 0.005,\n",
       " 'n_estimators': 25}"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.005, n_estimators=25, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Fitting Final Model on training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tunedRF = RandomForestClassifier(n_estimators = best_parameters[\"n_estimators\"],\n",
    "                                 criterion = best_parameters[\"criterion\"],\n",
    "                                 max_depth = best_parameters[\"max_depth\"],\n",
    "                                 min_samples_split = best_parameters[\"min_samples_split\"],\n",
    "                                 min_samples_leaf = best_parameters[\"min_samples_leaf\"],\n",
    "                                 min_weight_fraction_leaf = best_parameters[\"min_weight_fraction_leaf\"])\n",
    "tunedRF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Tuned RF: \n",
      " [[15036    13]\n",
      " [ 1249   145]]\n",
      "Accuracy for Tuned RF: \n",
      " 0.9232500152040382\n",
      "Precision for Tuned RF: \n",
      " 0.9177215189873418\n",
      "Recall for Tuned RF: \n",
      " 0.10401721664275466\n",
      "f1_score for Tuned RF: \n",
      " 0.18685567010309279\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix for Tuned RF: \\n',confusion_matrix(y_test, tunedRF.predict(X_test)))\n",
    "print('Accuracy for Tuned RF: \\n',accuracy_score(y_test, tunedRF.predict(X_test)))\n",
    "acc.append(accuracy_score(y_test, tunedRF.predict(X_test)))\n",
    "print('Precision for Tuned RF: \\n',precision_score(y_test, tunedRF.predict(X_test)))\n",
    "precision.append(precision_score(y_test, tunedRF.predict(X_test)))\n",
    "print('Recall for Tuned RF: \\n',recall_score(y_test, tunedRF.predict(X_test)))\n",
    "recall.append(recall_score(y_test, tunedRF.predict(X_test)))\n",
    "print('f1_score for Tuned RF: \\n',f1_score(y_test, tunedRF.predict(X_test)))\n",
    "f1.append(f1_score(y_test, tunedRF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
